{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "1P43NJk6Sxoi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUm79C0jS2La"
   },
   "outputs": [],
   "source": [
    "dataset, info = tfds.load('imdb_reviews', with_info=True,\n",
    "                          as_supervised=True)\n",
    "train_dataset, test_dataset = dataset['train'], dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_xakY9rDMFkt",
    "outputId": "9b47cc87-5a45-4f79-8958-b1c9d7b20727"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
      "label:  0\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "  print('text: ', example.numpy())\n",
    "  print('label: ', label.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O30JgDnnS78N"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMpQnJKsJgyR",
    "outputId": "1ef25e31-cfee-4368-be2f-9ccfc7f01c58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts:  [b'My take on this, at our local festival where people would see me so often they thought me a better source than I may actually have been, began with a head shake: \"Well, I can\\'t summarize the plot, but it\\'s a really superb character study of an extremely scary man.\" Then, slight embarrassment, I ran into someone who actually knew what had gone down, that is, from whom Trebor unwittingly gets his new heart. It\\'d been my last film in a long, long day halfway through the festival. Maybe I\\'d dozed. The better a film is the more likely it triggers daydreams that send me really dreaming. Don\\'t know. Did know there was an O\\'Henry twist achingly just beyond my ken as things finished. And knew it had to do with the heart, hence the quietly hilarious talent search. My plot-loss remark had more to do with intricacies of Trebor\\'s connections in France, his relation to the dog woman and so on, stuff I\\'d been wide awake for. Denis barely glances at details that might have anchored another director\\'s treatment.<br /><br />But I write these things too often from memory, especially festival films, films whose DVD I don\\'t have at hand (Le Lait de la tendresse humaine is one of many examples.), and plot kinks fade much more quickly than broader impressions. Still, or already, L\\'Inrus in my memory is beyond all else a character study of a sort of dark-side superman, a super fiend not ensconced in genre or historical trappings but active and plausible, relatively soft-spoken, driven but patient, right among us. The scar, once he attains it, makes him, just visually I mean, in image, a sort of hybrid Frankenstein monster, mad doctor and creation all in one. The actual doctors are his tools. If he doesn\\'t extract and install the heart himself, it\\'s only because it\\'s not possible. He\\'s the force, always, the parasite consuming everyone he touches and finally himself. What else is he? To suggest that he\\'s us, the First World versus the Third, seems too simple since he feeds no less on his fellow First Worlders, on all of us.<br /><br />Denis\\'s camera\\'s eye - when it looks at things I know - goes usually where mine would, so I tend to trust her when she looks at things I don\\'t know. Snow trekking, too-fast bicycling, and forest darkness I\\'ve known in small ways, but the South Seas not at all, so I made better entry into L\\'Intrus, both France and the crystalline isles of its finish, than into Beau Travail. L\\'Intrus is, for me, a very comfortable discomforting film. It\\'s a sequence of places portrayed familiarly, with a intimacy that allows us to know them whether we\\'ve seen the reality or not. A single image, Trebor cycling, his massive weight on the thin racing frame, the sounds of violated air and shrieking tires, the asphalt ribbon, the dark-in-bright-sun evergreens, cued me that the film would be linear, a road trip, a single will-driven thrust.<br /><br />Despite Trebor\\'s personal power, he\\'s a human failure. No matter who he\\'s with, he\\'s alone, though apparently he hasn\\'t always been. His body aborts life twice, first to need the new heart, then despite it. L\\'Intrus is tragedy. Trebor is hubris.<br /><br />I\\'m navigating perilously the thread of what I remember. Let\\'s leave it at that.'\n",
      " b\"To call a film about a crippled ghost taking revenge from beyond the grave lame and lifeless would be too ironical but this here is an undeniably undistinguished combination of GASLIGHT (1939 & 1944) via LES DIABOLIQUES (1954); while still watchable in itself, it's so clich\\xc3\\xa9-ridden as to provoke chuckles instead of the intended chills. However, thanks to the dire straits in which the British film industry found itself in the late 1970s, even a mediocre script such as this one was able to attract 10 star names - Cliff Robertson (as the conniving husband), Jean Simmons (in the title role), Jenny Agutter (as Robertson's artist half-sister), Simon Ward (as the enigmatic chauffeur), Ron Moody (as an ill-fated doctor), Michael Jayston (as Robertson's business partner), Judy Geeson (as Simmons' best friend and Jayston's wife), Flora Robson (as the housekeeper), David Tomlinson (as the notary reading Simmons' will) and, most surprisingly perhaps, Jack Warner (as a gravestone sculptor) - although most of them actually have nothing parts, I'm sorry to say!\"\n",
      " b'For the first couple of seasons, I thought The Apprentice was a highly engaging and exciting show. The combination between reality TV and a 16 week job-interview was innovative, and the producers of the show managed to keep the show relevant and not too \"out there\".<br /><br />The new season 6 is nothing more than a big joke and it has absolutely nothing to do with business - at all. In the earlier seasons they used to put a lot more emphasis on the business-related tasks - now the focus is mostly in the boardroom where the contestants are expected to do EVERYTHING to keep them on the show (that means lying, trash-talking, backstabbing etc.). The boardroom can be entertaining to watch, but it\\'s entertainment at it\\'s low-point - Sometimes you wonder if you are watching a repeat of an old Jerry Springer episode. The tasks on the show are, at most, boring and mostly a showcase for the companies who are dumb enough to pay NBC for the publicity. And what is the deal about half of the contestants living in tents in season 6? That is just plain stupid and has nothing to do with business in real-life. <br /><br />I have absolutely NO respect for any of the contestants this season, they all seem like idiots to me. In earlier seasons at least some of the contestants had a bit of integrity, now it seems like the contestants would kill their own mother to keep them on the show. It also seems like Donald Trump\\'s massive ego becomes bigger and bigger for every season that pass by and to be honest, I can\\'t see why anyone with a common sense would want to work for him. His rationality in the boardroom mostly doesn\\'t make any sense at all and sometimes it seems he just like to trash people for what it\\'s worth.<br /><br />R.I.P The Apprentice. Please NBC, for God\\'s sake, get the show off the air as soon as possible. It\\'s just too embarrassing to watch. The Apprentice was once a great TV-show, but now it\\'s just a big fat joke.']\n",
      "\n",
      "labels:  [1 0 0]\n"
     ]
    }
   ],
   "source": [
    "for example, label in train_dataset.take(1):\n",
    "  print('texts: ', example.numpy()[:3])\n",
    "  print()\n",
    "  print('labels: ', label.numpy()[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nl9ZADDhTKXg"
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "geTlt1F4M0NR",
    "outputId": "c21504cc-e450-4490-e89c-91edb04b5686"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'the', 'and', 'a', 'of', 'to', 'is', 'in', 'it', 'i',\n",
       "       'this', 'that', 'br', 'was', 'as', 'for', 'with', 'movie', 'but'],\n",
       "      dtype='<U14')"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZfXc1uoTRPk"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=64,\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cVyseiRxJvzZ",
    "outputId": "b370c085-82e7-4e0a-88e6-9cc1ba9fdc31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17260222]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sample_text = ('very good movie.must watch it')\n",
    "predictions = model.predict(np.array([sample_text]))\n",
    "print(predictions[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5AR2hdQKTVD9"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilFzHUySTdcx",
    "outputId": "e70308e7-f841-425f-cd45-23ce2f57f213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 687s 2s/step - loss: 0.6856 - accuracy: 0.5096 - val_loss: 0.5340 - val_accuracy: 0.6865\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=1,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=30)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "new_model_miniproject.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
